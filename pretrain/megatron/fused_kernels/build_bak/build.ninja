ninja_required_version = 1.3
cxx = c++
nvcc = /usr/local/cuda/bin/nvcc

cflags = -DTORCH_EXTENSION_NAME=fused_mix_prec_layer_norm_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /zhangpai26/pkgs/torch/include -isystem /zhangpai26/pkgs/torch/include/torch/csrc/api/include -isystem /zhangpai26/pkgs/torch/include/TH -isystem /zhangpai26/pkgs/torch/include/THC -isystem /usr/local/cuda/include -isystem /root/miniconda3/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3
post_cflags = 
cuda_cflags = -DTORCH_EXTENSION_NAME=fused_mix_prec_layer_norm_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /zhangpai26/pkgs/torch/include -isystem /zhangpai26/pkgs/torch/include/torch/csrc/api/include -isystem /zhangpai26/pkgs/torch/include/TH -isystem /zhangpai26/pkgs/torch/include/THC -isystem /usr/local/cuda/include -isystem /root/miniconda3/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 --use_fast_math -maxrregcount=50 -std=c++14
cuda_post_cflags = 
ldflags = -shared -L/zhangpai26/pkgs/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda_cu -ltorch_cuda_cpp -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart

rule compile
  command = $cxx -MMD -MF $out.d $cflags -c $in -o $out $post_cflags
  depfile = $out.d
  deps = gcc

rule cuda_compile
  depfile = $out.d
  deps = gcc
  command = $nvcc  $cuda_cflags -c $in -o $out $cuda_post_cflags

rule link
  command = $cxx $in $ldflags -o $out

build layer_norm_cuda.o: compile /zhangpai26/100b_training/uniglm_100b/megatron/fused_kernels/layer_norm_cuda.cpp
build layer_norm_cuda_kernel.cuda.o: cuda_compile /zhangpai26/100b_training/uniglm_100b/megatron/fused_kernels/layer_norm_cuda_kernel.cu

build fused_mix_prec_layer_norm_cuda.so: link layer_norm_cuda.o layer_norm_cuda_kernel.cuda.o

default fused_mix_prec_layer_norm_cuda.so

